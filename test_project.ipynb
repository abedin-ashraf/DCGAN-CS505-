{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c9c753",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network\n",
    "\n",
    "In this project we are trying to achieve a Generative Adversarial Network (GAN) model using Deep convolutional technique. In this there are two models such Generator (an artist) and discriminator (an art critic) both the models are set as adversrial to each other to achive the result.\n",
    "\n",
    "In the first cell we are importing all the libraries that we need for the code to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d66e7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')      # Enabling GPU\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))  # Checking if GPU is available or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581c384",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "Here we are using the dataset called celeb_A which has 202599 images of celebrities. These images are of 178x218 resolution and 96dpi of pixel density. But for our project we are scaling down the images to 64x64 so that it won't stress the hardware much and runs the program faster.\n",
    "\n",
    "- For scaling down the image we are using the keras preprocessing fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b077842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"C:\\\\Users\\\\saika\\\\Documents\\\\Jupyter Files\\\\Project\\\\archive\\\\img_align_celeba\\\\img_align_celeba\",\n",
    "\tlabel_mode=None, image_size=(64, 64), batch_size=32,\n",
    "    shuffle=True\n",
    ").map(lambda x: x/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214ed15",
   "metadata": {},
   "source": [
    "### Discriminator \n",
    "\n",
    "The main goal of the discriminator is to determine whether the given images are fake or not by comparing the images to the genrated images with arrays of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a3ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(64, 64, 3)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67532135",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "The main goal of the genrator is to generate fake images and to trick the discriminate into making it belive the genrated images are real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2355a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(latent_dim,)),\n",
    "        tf.keras.layers.Dense(8*8*128),\n",
    "        tf.keras.layers.Reshape((8, 8, 128)),\n",
    "        tf.keras.layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(0.2),\n",
    "        tf.keras.layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ]                \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d6fb2",
   "metadata": {},
   "source": [
    "### Discrimator Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36ad581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3d19c",
   "metadata": {},
   "source": [
    "### Generator Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53bf651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              1056768   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113a98c",
   "metadata": {},
   "source": [
    "### Defining Learning rate\n",
    "\n",
    "Since we are setting two different models we are defining adam optimizer separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd5c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "opt_disc = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72e959",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Here we are training the model in a very generic way. Usually the model is trained to a very extensive range of epoch upto 100+ to see any better result but due to hardware and time restrictions the epoches are redduced to 20 to see faster results. Still with a GPU each epoch took 24~28 minutes.\n",
    "\n",
    "Once in a while the generated fake images are saved to the defined path so that output can be seen there. At initial stages of the training see lots of losses on the discriminator side, until the adequate traing has been given such as 100 epoch the losses can't be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6c22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6332/6332 [27:35<00:00,  3.82it/s]\n",
      "100%|██████████| 6332/6332 [27:25<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:25<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:25<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:26<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:25<00:00,  3.85it/s]\n",
      "100%|██████████| 6332/6332 [27:38<00:00,  3.82it/s]\n",
      "100%|██████████| 6332/6332 [27:35<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for index, real in enumerate(tqdm(dataset)):\n",
    "        batch_size = real.shape[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "        fake = generator(random_latent_vectors)\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            img = keras.preprocessing.image.array_to_img(fake[0])\n",
    "            img.save(\"C:\\\\Users\\\\saika\\\\Documents\\\\Jupyter Files\\\\Project\\\\Generated_images\\\\gen_img_%03d_%d.png\" % (epoch, index))\n",
    "\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            loss_disc_real = loss_fn(tf.ones((batch_size, 1)), discriminator(real))\n",
    "            loss_disc_fake = loss_fn(tf.zeros((batch_size, 1)), discriminator(fake))\n",
    "            loss_disc = (loss_disc_real + loss_disc_fake)/2\n",
    "\n",
    "        grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)\n",
    "        opt_disc.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake = generator(random_latent_vectors)\n",
    "            output = discriminator(fake)\n",
    "            loss_gen = loss_fn(tf.ones(batch_size, 1), output)\n",
    "\n",
    "        grads = gen_tape.gradient(loss_gen, generator.trainable_weights)\n",
    "        opt_gen.apply_gradients(zip(grads, generator.trainable_weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
